name: Ingest & Process Articles

on:
  # Run every 6 hours
  schedule:
    - cron: "0 */6 * * *"

  # Also allow manual trigger from the GitHub Actions UI
  workflow_dispatch:
    inputs:
      no_fulltext:
        description: "Skip full-text scraping (faster)"
        required: false
        default: "false"
        type: boolean

jobs:
  ingest:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install system dependencies
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y libxml2-dev libxslt1-dev libjpeg-dev zlib1g-dev

      - name: Install Python dependencies
        run: pip install -r requirements.txt

      - name: Fetch new articles
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          ARGS=""
          if [ "${{ github.event.inputs.no_fulltext }}" = "true" ]; then
            ARGS="--no-fulltext"
          fi
          python scripts/run_fetcher.py \
            --sources config/sources.yaml \
            --delay 1.5 \
            $ARGS

      - name: Categorise & extract entities
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: python scripts/process_articles.py
